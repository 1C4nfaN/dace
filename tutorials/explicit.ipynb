{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DaCe with Explicit Dataflow in Python\n",
    "\n",
    "In this tutorial, we will use the explicit dataflow specification in Python to construct DaCe programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit dataflow is a Python-based syntax that is close to defining SDFGs. In explicit ` @dace.program `s, the code (Tasklets) and memory movement (Memlets) are specified separately, as we show below.\n",
    "\n",
    "## Matrix Transposition\n",
    "\n",
    "We begin with a simple example, transposing a matrix (out-of-place). \n",
    "\n",
    "First, since we do not know what the matrix sizes will be, we define symbolic sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = dace.symbol('M')\n",
    "N = dace.symbol('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to define the data-centric part of the application (i.e., the part that can be optimized by DaCe). It is a simple function which, when called, invokes the compilation and optimization procedure. It can also be compiled explicitly, as we show in the next example.\n",
    "\n",
    "DaCe programs use explicit types, so that they can be compiled. We provide a numpy-compatible set of types that can define N-dimensional tensors. For example, `dace.int64` defines a 64-bit signed integer scalar, and `dace.float32[133,8]` defines a 133-row and 8-column 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dace.program\n",
    "def transpose(A: dace.float32[M, N], B: dace.float32[N, M]):\n",
    "    # Inside the function we will define a tasklet in a map, which is shortened\n",
    "    # to dace.map. We define the map range in the arguments:\n",
    "    @dace.map\n",
    "    def mytasklet(i: _[0:M], j: _[0:N]):\n",
    "        # Pre-declaring the memlets is required in explicit dataflow, tasklets\n",
    "        # cannot use any external memory apart from data flowing to/from it.\n",
    "        a << A[i,j]  # Input memlet (<<)\n",
    "        b >> B[j,i]  # Output memlet (>>)\n",
    "        \n",
    "        # The code\n",
    "        b = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! We will now define some regression test using numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.random.rand(37, 11).astype(np.float32)\n",
    "expected = A.transpose()\n",
    "# Define an array for the output of the dace program\n",
    "B = np.random.rand(11, 37).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we call `transpose`, we can inspect the SDFG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically applied 1 strict state fusions and removed 0 redundant arrays.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: SDFG Pages: 1 -->\n",
       "<svg width=\"392pt\" height=\"544pt\"\n",
       " viewBox=\"0.00 0.00 392.00 543.64\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 539.6371)\">\n",
       "<title>SDFG</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-539.6371 388,-539.6371 388,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_state_0</title>\n",
       "<polygon fill=\"#deebf7\" stroke=\"#deebf7\" points=\"8,-8 8,-527.6371 376,-527.6371 376,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"341\" y=\"-512.4371\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mytasklet</text>\n",
       "</g>\n",
       "<!-- s0_3 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>s0_3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"#000000\" points=\"89.213,-103 294.787,-103 368,-177 16,-177 89.213,-103\"/>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"157,-151 157,-166 228,-166 228,-151 157,-151\"/>\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-156\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">IN_1</text>\n",
       "<text text-anchor=\"start\" x=\"123\" y=\"-135.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mytasklet[i=0:M, j=0:N]</text>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"154,-114 154,-129 231,-129 231,-114 154,-114\"/>\n",
       "<text text-anchor=\"start\" x=\"176.5\" y=\"-119\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">OUT_1</text>\n",
       "</g>\n",
       "<!-- s0_4 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>s0_4</title>\n",
       "<ellipse fill=\"#ffffff\" stroke=\"#000000\" stroke-width=\"2\" cx=\"193\" cy=\"-34\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B</text>\n",
       "</g>\n",
       "<!-- s0_3&#45;&gt;s0_4 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>s0_3:OUT_1&#45;&gt;s0_4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M193,-114C193,-96.9004 193,-77.7449 193,-62.4659\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"196.5001,-62.1103 193,-52.1104 189.5001,-62.1104 196.5001,-62.1103\"/>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-73.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B[0:N, 0:M]</text>\n",
       "</g>\n",
       "<!-- s0_1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>s0_1</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"#000000\" points=\"294.787,-409.6371 89.213,-409.6371 16,-335.6371 368,-335.6371 294.787,-409.6371\"/>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"157,-383.6371 157,-398.6371 228,-398.6371 228,-383.6371 157,-383.6371\"/>\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-388.6371\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">IN_1</text>\n",
       "<text text-anchor=\"start\" x=\"123\" y=\"-368.4371\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mytasklet[i=0:M, j=0:N]</text>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"154,-346.6371 154,-361.6371 231,-361.6371 231,-346.6371 154,-346.6371\"/>\n",
       "<text text-anchor=\"start\" x=\"176.5\" y=\"-351.6371\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">OUT_1</text>\n",
       "</g>\n",
       "<!-- s0_2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>s0_2</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"#000000\" points=\"262.3276,-244.6633 262.3276,-267.9738 221.1306,-284.4569 162.8694,-284.4569 121.6724,-267.9738 121.6724,-244.6633 162.8694,-228.1803 221.1306,-228.1803 262.3276,-244.6633\"/>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"177,-267.3186 177,-282.3186 208,-282.3186 208,-267.3186 177,-267.3186\"/>\n",
       "<text text-anchor=\"start\" x=\"190\" y=\"-272.3186\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">a</text>\n",
       "<text text-anchor=\"start\" x=\"165\" y=\"-252.1186\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mytasklet</text>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"176,-230.3186 176,-245.3186 208,-245.3186 208,-230.3186 176,-230.3186\"/>\n",
       "<text text-anchor=\"start\" x=\"189\" y=\"-235.3186\" font-family=\"Times,serif\" font-size=\"10.00\" fill=\"#000000\">b</text>\n",
       "</g>\n",
       "<!-- s0_1&#45;&gt;s0_2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>s0_1:OUT_1&#45;&gt;s0_2:a</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M193,-346.6371C193,-321.736 193,-313.1033 193,-292.3964\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"196.5001,-292.3185 193,-282.3186 189.5001,-292.3186 196.5001,-292.3185\"/>\n",
       "<text text-anchor=\"middle\" x=\"210\" y=\"-306.4371\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">A[i, j]</text>\n",
       "</g>\n",
       "<!-- s0_0 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>s0_0</title>\n",
       "<ellipse fill=\"#ffffff\" stroke=\"#000000\" stroke-width=\"2\" cx=\"193\" cy=\"-478.6371\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-474.9371\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">A</text>\n",
       "</g>\n",
       "<!-- s0_0&#45;&gt;s0_1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>s0_0&#45;&gt;s0_1:IN_1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M193,-460.5268C193,-446.8457 193,-427.3195 193,-408.7872\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"196.5001,-408.6371 193,-398.6371 189.5001,-408.6372 196.5001,-408.6371\"/>\n",
       "<text text-anchor=\"middle\" x=\"228\" y=\"-431.4371\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">A[0:M, 0:N]</text>\n",
       "</g>\n",
       "<!-- s0_2&#45;&gt;s0_3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>s0_2:b&#45;&gt;s0_3:IN_1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M192,-230.3186C192,-205.4144 192.7588,-196.7866 192.9544,-176.0787\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"196.4547,-176.0158 193,-166 189.4547,-175.984 196.4547,-176.0158\"/>\n",
       "<text text-anchor=\"middle\" x=\"209\" y=\"-198.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B[j, i]</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<dace.sdfg.SDFG at 0x7f153e77ecc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdfg = transpose.to_sdfg()\n",
    "sdfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call `transpose` directly, or using the SDFG we created. When calling `transpose`, we need to feed the symbols as well as the arguments (since the arrays are `numpy` rather than symbolic `dace` arrays, see below tutorials). When prompted for transformations, we will now just press the \"Enter\" key to skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Pattern FPGATransformSDFG in transpose\n",
      "1. Pattern FPGATransformState in mytasklet\n",
      "2. Pattern GPUTransformState in transpose\n",
      "3. Pattern NestSDFG in transpose\n",
      "4. Pattern FPGATransformMap in mytasklet[i=0:M, j=0:N]\n",
      "5. Pattern GPUTransformLocalStorage in mytasklet[i=0:M, j=0:N]\n",
      "6. Pattern GPUTransformMap in mytasklet[i=0:M, j=0:N]\n",
      "7. Pattern MapExpansion in mytasklet: ['i', 'j']\n",
      "8. Pattern OrthogonalTiling in mytasklet: ['i', 'j']\n",
      "9. Pattern StripMining in mytasklet: ['i', 'j']\n",
      "Select the pattern to apply (0 - 9 or name$id): \n",
      "You did not select a valid option. Quitting optimization ...\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /path/to/dace/tutorials/.dacecache/transpose/build\n",
      "\n",
      "[ 50%] Built target dacestub\n",
      "Scanning dependencies of target transpose\n",
      "[ 75%] Building CXX object CMakeFiles/transpose.dir/path/to/dace/tutorials/.dacecache/transpose/src/cpu/transpose.cpp.o\n",
      "[100%] Linking CXX shared library libtranspose.so\n",
      "[100%] Built target transpose\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdfg(A=A, B=B, M=A.shape[0], N=A.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Difference:', np.linalg.norm(expected - B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query (using Streams)\n",
    "\n",
    "In this example, we will use the Stream construct and symbolic dace ND arrays to create a simple parallel filter. We first define a symbolic size and a symbolically-sized array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = dace.symbol('N')\n",
    "\n",
    "storage = dace.ndarray(shape=[N], dtype=dace.int32)\n",
    "# The size of \"output\" will actually be lesser or equal to N, but we need to \n",
    "# statically allocate the memory.\n",
    "output = dace.ndarray(shape=[N], dtype=dace.int32)\n",
    "# The size is a scalar\n",
    "output_size = dace.scalar(dtype=dace.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with `transpose`, the DaCe program also consists of a tasklet nested in a Map, but also includes a Stream (to which we push outputs as necessary) that is directly connected to the output array, as well as a conflict-resolution output (because all tasklets in the map write to the same address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dace.program\n",
    "def query(data: dace.int32[N], output: dace.int32[N], outsz: dace.int32[1], \n",
    "          threshold: dace.int32):\n",
    "    # Define a local, unbounded (buffer_size=0) stream\n",
    "    S = dace.define_stream(dace.int32, 0)\n",
    "    \n",
    "    # Define a memlet from S to the output\n",
    "    S >> output\n",
    "    \n",
    "    # Filtering tasklet\n",
    "    @dace.map\n",
    "    def filter(i: _[0:N]):\n",
    "        a << data[i]\n",
    "        # Writing to S (no location necessary) a dynamic number of times (-1)\n",
    "        out >> S(-1)\n",
    "        # Writing to outsz dynamically (-1), if there is a conflict, we will sum the results\n",
    "        osz >> outsz(-1, lambda a,b: a+b)   \n",
    "        \n",
    "        if a > threshold:\n",
    "            # Pushing to a stream or writing with a conflict use the assignment operator\n",
    "            out = a\n",
    "            osz = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compile `query` without defining anything further. However, before we call `query`, we will need to set the symbol sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically applied 1 strict state fusions and removed 0 redundant arrays.\n",
      "0. Pattern FPGATransformSDFG in query\n",
      "1. Pattern FPGATransformState in filter\n",
      "2. Pattern GPUTransformState in query\n",
      "3. Pattern NestSDFG in query\n",
      "4. Pattern FPGATransformMap in filter[i=0:N]\n",
      "5. Pattern GPUTransformLocalStorage in filter[i=0:N]\n",
      "6. Pattern GPUTransformMap in filter[i=0:N]\n",
      "7. Pattern MPITransformMap in filter\n",
      "8. Pattern MapToForLoop in filter: ['i']\n",
      "9. Pattern OrthogonalTiling in filter: ['i']\n",
      "10. Pattern StripMining in filter: ['i']\n",
      "11. Pattern Vectorization in 1 -> 2 -> 3\n",
      "Select the pattern to apply (0 - 11 or name$id): \n",
      "You did not select a valid option. Quitting optimization ...\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /path/to/dace/tutorials/.dacecache/query/build\n",
      "\n",
      "[ 50%] Built target dacestub\n",
      "Scanning dependencies of target query\n",
      "[ 75%] Building CXX object CMakeFiles/query.dir/path/to/dace/tutorials/.dacecache/query/src/cpu/query.cpp.o\n",
      "/path/to/dace/tutorials/.dacecache/query/src/cpu/query.cpp: In function ‘void __program_query_internal(int*, int*, int*, int, int)’:\n",
      "/path/to/dace/tutorials/.dacecache/query/src/cpu/query.cpp:19:23: warning: unused variable ‘out’ [-Wunused-variable]\n",
      "                 auto &out = __out;\n",
      "                       ^~~\n",
      "/path/to/dace/tutorials/.dacecache/query/src/cpu/query.cpp:21:23: warning: unused variable ‘osz’ [-Wunused-variable]\n",
      "                 auto &osz = __osz.ref<1>();\n",
      "                       ^~~\n",
      "[100%] Linking CXX shared library libquery.so\n",
      "[100%] Built target query\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qfunc = query.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N.set(255)\n",
    "thres = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some random integers and zero outputs\n",
    "import numpy as np\n",
    "storage[:] = np.random.randint(0, 100, size=N.get())\n",
    "output_size[0] = 0\n",
    "output[:] = np.zeros(N.get()).astype(np.int32)\n",
    "\n",
    "# Compute expected output using numpy\n",
    "expected = storage[np.where(storage > thres)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will just use the Python function prototype to call the code, since we do not invoke it through the SDFG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ndarray([131], dtype=uint32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qfunc(storage, output, output_size, thres)\n",
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "filtered_output = output[:output_size[0]]\n",
    "# Sorting outputs to avoid concurrency-based reordering\n",
    "print('Difference:', np.linalg.norm(np.sort(expected) - np.sort(filtered_output)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
